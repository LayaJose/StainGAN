{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import progressbar\n",
    "import os.path\n",
    "\n",
    "import pyvips\n",
    "import numpy as np\n",
    "import  requests, json, os\n",
    "import glob\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "path = \"/home/amir/project/tcga_patches/\"\n",
    "converted_files = \"/home/amir/project/pytorch-CycleGAN-and-pix2pix/tmad/all_stain_cyclegan/test_1/images/\"\n",
    "\n",
    "X=[]\n",
    "X_processed=[]\n",
    "Y=[]\n",
    "X_train = None\n",
    "Y_train = None\n",
    "\n",
    "classes = {}\n",
    "\n",
    "im = \"\"\n",
    "\n",
    "def adjust_image(im):\n",
    "    imgs = im.resize((299, 299), Image.ANTIALIAS)\n",
    "    return imgs\n",
    "\n",
    "for directory in os.listdir(path):\n",
    "    print(directory)\n",
    "    for file in os.listdir(path + directory)[:300]:\n",
    "        converted_file = converted_files + file[:-4] + \"_fake_B.png\"        \n",
    "        if(os.path.exists(converted_file)):\n",
    "            img = Image.open(path + directory + \"/\" + file).convert(\"RGB\")\n",
    "            img = adjust_image(img)\n",
    "            features=np.array(img, dtype=np.float32)/255.0\n",
    "            processed_img = Image.open(converted_file)\n",
    "            processed_img = adjust_image(processed_img)\n",
    "            processed_feature=np.array(processed_img, dtype=np.float32)/255.0\n",
    "            X_processed.append(processed_feature)\n",
    "            X.append(features)\n",
    "            if directory in classes:\n",
    "                class_id = classes[directory]\n",
    "            else:\n",
    "                class_id = len(classes.keys())\n",
    "                classes[directory] = class_id\n",
    "            Y.append(class_id)\n",
    "\n",
    "\n",
    "print(\"Read all of data.\")\n",
    "            \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "X_processed_train, X_processed_test, y_processed_train, y_processed_test = train_test_split(X_processed, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_processed_train = np.array(X_processed_train)\n",
    "X_processed_test = np.array(X_processed_test)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_processed_train, X_processed_test, y_processed_train, y_processed_test = train_test_split(X_processed, Y, test_size=0.33, random_state=42)\n",
    "X_processed_train = np.array(X_processed_train)\n",
    "X_processed_test = np.array(X_processed_test)\n",
    "X_processed = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "def inceptionv3_model_fn(features, labels, mode):\n",
    "    # Load Inception-v3 model.\n",
    "    module = hub.Module(\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1\")\n",
    "    input_layer = features[\"x\"]\n",
    "    outputs = module(input_layer)\n",
    "    logits = tf.layers.dense(inputs=outputs, units=NUM_CLASSES)\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])\n",
    "    tf.summary.scalar(\"accuracy\", accuracy[1])\n",
    "    \n",
    "    \n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"accuracy\": accuracy[1]}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=100)\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, training_hooks=[logging_hook])\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": accuracy}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "\n",
    "def run_graph(X_train_, y_train_, X_test_, y_test_, log_dir, epochs):\n",
    "    with tf.Graph().as_default() as g:\n",
    "            # create input functions for train and evaluate methods.\n",
    "            train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                x={\"x\": X_train_},\n",
    "                y=y_train_,\n",
    "                batch_size=40,\n",
    "                num_epochs=None,\n",
    "                shuffle=True)\n",
    "            eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                x={\"x\": X_test_},\n",
    "                y=y_test_,\n",
    "                num_epochs=1,\n",
    "                shuffle=False)\n",
    "\n",
    "            # Create an estimator\n",
    "            classifier = tf.estimator.Estimator(\n",
    "                model_fn=inceptionv3_model_fn, model_dir=log_dir)\n",
    "            \n",
    "            for i in range(epochs):\n",
    "                print(\"Epoc %i...\" % i)\n",
    "                # Train network.\n",
    "                classifier.train(\n",
    "                    input_fn=train_input_fn,\n",
    "                    steps=200)\n",
    "\n",
    "                # Evaluate the model and print results.\n",
    "                eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "run_graph(X_train, y_train, X_test, y_test, \"cameliyon\", 50)\n",
    "run_graph(X_processed_train, y_train, X_processed_test, y_test, \"cameliyon_processed\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
